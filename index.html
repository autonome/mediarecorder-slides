<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Real time front-end alchemy - Soledad PenadÃ©s</title>
		<link rel="stylesheet" href="vendor/prism/prism.css">
		<script src="vendor/prism/prism.js"></script>
		<link rel="stylesheet" href="css/style.css">
	</head>
	<body>
		<main>
			<section class="intro">
				<h1>Real time front-end alchemy</h1>
				<h2>Soledad PenadÃ©s</h2>
				<h3><a href="https://soledadpenades.com">soledadpenades.com</a> / @supersole</h3>
			</section>

			<section>
				<h1>Real time front-end alchemy</h1>
				<h2><em>or:</em> creating and manipulating streams</h2>
			</section>
			
			<section class="splash background-image" data-background="imgs/streams.png">
				<h1>Streams!?!</h1>
			</section>

			<section>
				<div>
					<h2>Not:</h2>
					<ul>
						<li>Node.js streams</li>
						<li>Future JavaScript streams</li>
					</ul>
				</div>
				<div>
					<h2>Yes:</h2>
					<ul>
						<li><tt>MediaStream</tt>s</li>
					</ul>
				</div>
			</section>
			
			<!-- getUserMedia -->
			<section class="splash">
				<h1><tt>getUserMedia</tt></h1>
			</section>

			<section>
				<h2><tt>getUserMedia</tt></h2>
				<pre>
					<code class="language-js">
						navigator.mediaDevices.getUserMedia({
							 audio: true,
							 video: true
						}).then(function (stream) {
							// do something with the stream
						}
					</code>
				</pre>
			</section>

			<section class="two-rows">
				<pre>
					<code class="language-js">
						navigator.mediaDevices.getUserMedia({
							audio: true,
							video: true
						}).then(function (stream) {
							var video = document.createElement('video');
							document.body.appendChild(video);
							video.src = URL.createObjectURL(stream);
							video.play();
						}
					</code>
				</pre>
				<div><iframe data-src="examples/display-webcam.html"></iframe></div>
			</section>

			<section>
				<h2>... this is old news ðŸ˜´</h2>
			</section>

			<section>
				<h1>ðŸ†• and ðŸ†’: <tt>MediaRecorder</tt></h1>
			</section>

			<section class="two-rows">
				<pre>
					<code class="language-js">
						var recorder = new MediaRecorder(stream);
						recorder.addEventListener('dataavailable', e => {
							video.src = URL.createObjectURL(e.data);
							video.play();
						});
						recorder.start();
						setTimeout(() => {
							recorder.stop();
						}, 1000);
					</code>
				</pre>
				<div>
					<iframe data-src="examples/record-av.html"></iframe>
				</div>
			</section>

			<section class="splash">
				<h1>I just encoded audio and video natively in the browser, without plug-ins.</h1>
			</section>
			
			<section class="splash">
				<h1>You can get really creative with this!<br />For example...</h1>
			</section>

			<section class="fullscreen-demo">
				<div><iframe data-src="examples/looping-mosaic.html"></iframe></div>
			</section>
			
			<section>
				<h1><tt>MediaRecorder</tt> doesn't care about where the <tt>stream</tt> comes from</h1>
			</section>

			<section>
				<h1>Let's use it to record streams from other sources: <tt>canvas.captureStream()</tt></h1>
			</section>

			<section class="two-rows">
				<pre>
					<code class="language-js">
						// Not shown: drawing white noise on the canvas
						// [...]
						var canvasStream = canvas.captureStream(30); // fps
						var recorder = new MediaRecorder(canvasStream);
					</code>
				</pre>
				<div>
					<iframe data-src="examples/record-canvas.html"></iframe>
				</div>
			</section>

			<section>
				<h1>We can also transform webcam images with <tt>canvas</tt> pixel manipulation</h1>
			</section>

			<section class="two-rows">
				<pre>
					<code class="language-js">
					context.drawImage(video, 0, 0, width, height); // draw video into canvas
					
					var imageData = context.getImageData(0, 0, width, height);
					var data = imageData.data;
					for (var i = 0; i < data.length; i+=4) {
						data[i] = data[i] >= cutOff ? 255 : 0; // red
						data[i + 1] = data[i + 1] >= cutOff ? 255 : 0; // green
						data[i + 2] = data[i + 2] >= cutOff ? 255 : 0; // blue
					}
					</code>
				</pre>
				<div>
					<iframe data-src="examples/canvas-pixel-manipulation.html"></iframe>
				</div>
			</section>

			<section>
				<h1>And we can record the output of this canvas, using <tt>captureStream</tt> on it</h1>
			</section>

			<section class="two-rows">
				<pre>
					<code class="language-js">
					// some steps from before, combined
					// 1. init webcam
					// 2. make video stream
					// 3. copy to canvas and alter pixels
					// 4. get stream from canvas
					// 5. record!
					</code>
				</pre>
				<div>
					<iframe data-src="examples/canvas-pixel-manipulation-and-record.html"></iframe>
				</div>
			</section>

			<section>
				<h1>You should not use <tt>canvas</tt> 2D pixel manipulation for this because it can be really slow. Use WebGL!</h1>
				<h2>(but WebGL takes longer to setup and learn and explain, and won't fit on slides, so...)</h2>
			</section>

			<section>
				<h1>Likewise, we can modify audio in real time, using an <tt>AudioContext</tt></h1>
			</section>

			<section>
				<h1><tt>AudioContext</tt> is your door<br />to the power of Web Audio</h1>
				<h2>It lets you <strong>create</strong> input and output <strong>nodes</strong> and <strong>connect</strong> them together to form an <strong>audio graph</strong> to <strong>route</strong> and <strong>manipulate</strong> sounds in various ways.</h2>
				<h3>I cannot explain Web Audio to you in two minutes, so this will have to do!</h3>
			</section>

			<section>
				<h1>This is what we're going to do:</h1>
				<h2><tt>stream -&gt; audio context -&gt; stream</tt></h2>
			</section>

			<section>
				<h1>But we'll start with:</h1>
				<h2><tt>stream -&gt; audio context</tt></h2>
			</section>

			<section>
				<pre>
					<code class="language-js">
					// assume we obtained a stream from the webcam
					var ac = new AudioContext();
					var inputNode = audioContext.createMediaStreamSource(stream);
					var flanger = makeFlanger(audioContext);
					// [...]
					//  ^^^  not shown: ~40 lines to build the flanger
					inputNode.connect(flanger.input);
					flanger.output.connect(ac.destination);
					</code>
				</pre>
				<div><iframe data-src="examples/filter-live-audio.html"></iframe></div>
			</section>


			<section>
				<h1>Let's add a <tt>stream</tt> to record this:</h1>
				<h2><tt>stream -&gt; audio context <ins>-&gt; stream</ins></tt></h2>
			</section>

			<section>
				<pre>
					<code class="language-js">
						var outputNode = audioContext.createMediaStreamDestination();
						filter.output.connect(outputNode);

						var recorder = new MediaRecorder(outputNode.stream);
						// and record as usual...
						recorder.start();
					</code>
				</pre>
				<div><iframe data-src="examples/filter-and-record-live-audio.html"></iframe></div>
			</section>

			<section>
				<h1>we know how to manipulate and<br />record video, and audio</h1>
				<h2>but how to do it all together?</h2>
			</section>
			<section>
				<h1>When we process audio and video in parallel, we end up with <em>two</em> streams, but <tt>MediaRecorder</tt> only takes <em>one</em>...</h1>
			</section>

			<section>
				<h1>What is  âœ¨the ultimate secretâœ¨<br />to real time front-end alchemy?</h1>
			</section>
			
			<section>
				<h1><tt>MediaStream</tt></h1>
			</section>

			<section>
				<h2><tt>MediaStream</tt></h2>
				<ul>
					<li>we can create instances, as we have access to the constructor</li>
					<li>each instance has <em>very</em> useful methods
						<ul>
							<li><tt>getAudioTracks()</tt></li>
							<li><tt>getVideoTracks()</tt></li>
							<li><tt>addTrack()</tt></li>
							<li>etc...</li>
						</ul>
					</li>
				</ul>
			</section>
			
			<section>
				<h1>With this, we can recombine any number of streams into just one and keep on recording!</h1>
				<h2>(as <tt>MediaRecorder</tt> doesn't care where did the stream come from)</h2>
			</section>

			<section>
				<pre>
					<code class="language-js">
					// Video =========================
					var videoStream = new MediaStream();
					var videoTracks = inputStream.getVideoTracks();
					videoTracks.forEach(function(track) {
						videoStream.addTrack(track);
					});
					// [...] manipulate videoStream into a canvas
					// then get result from canvas stream into videoOutputStream
					var videoOutputStream = videoCanvas.captureStream();
					</code>
				</pre>
			</section>
			<section>
				<pre>
					<code class="language-js">
					// Audio =========================
					var audioStream = new MediaStream();
					var audioTracks = inputStream.getAudioTracks();
					audioTracks.forEach(function(track) {
						audioStream.addTrack(track);
					});
					// [...] manipulate audio with an audio context
					// then get result from audio destination node into audioOutputStream
					var audioOutputStream = streamDestination.stream;
					</code>
				</pre>
			</section>

			<section>
				<pre>
					<code class="language-js">
					// Merging into one stream only ==
					var outputStream = new MediaStream();
					[audioOutputStream, videoOutputStream].forEach(function(s) {
						s.getTracks().forEach(function(t) {
							outputStream.addTrack(t);
						});
					});
					</code>
				</pre>
			</section>

			<section>
				<pre>
					<code class="language-js">
					// And recording! ================
					var finalRecorder = new MediaRecorder(outputStream);
					</code>
				</pre>
			</section>

			<section>
				<h1><tt>MediaRecorder</tt> + <tt>Web Audio</tt> + <tt>WebGL</tt> enable you to build really sophisticated apps without plugins or server side support<br />so it's faster and respectful of your users' privacy</h1>
			</section>
			<section>
				<h1>Example: Boo</h1>
				<h2>A videobooth built with WebGL and Web Audio</h2>
				<a href="https://mozdevs.github.io/boo/"><img src="imgs/boo.png" alt="Boo videobooth" /></a>
			</section>

			<section>
				<h1>Wrap up</h1>
				<h2>The MediaCapture API is very cool!</h2>
			</section>
		
			<section>
				<h1>Wrap up</h1>
				<h2>Support is so so:</h2>
				<ul>
					<li>Firefox supports everything I showed you (obviously)</li>
					<li>Chrome can record audio and video streams (but not coming from WebAudio or canvas)</li>
					<li>Safari lolsob ðŸ˜‚ðŸ˜¥</li>
					<li>Internet Explorer: not in your dreams, but MS Edge seems open to develop this</li>
					<li>Support on mobile (Firefox/Chrome on Android) can be a bit hit and miss, and there's no hardware acceleration yet for the encoding, but things are getting better</li>
					<li>I've no idea about Windows Phone or Blackberry</li>
					<li>I don't think Opera Mini will support this</li>
					<li>Definitely not in Lynx</li>
				</ul>
			</section>

			<section>
				<h1>More resources</h1>
				<ul>
					<li><a href="https://hacks.mozilla.org/2016/04/record-almost-everything-in-the-browser-with-mediarecorder/">Record almost everything in the browser with MediaRecorder</a></li>
					<li><a href="https://mozdevs.github.io/MediaRecorder-examples/">Media recorder examples</a> collection</li>
					<li><a href="https://mozdevs.github.io/boo/">Boo!</a></li>
					<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder_API">MDN MediaRecorder API documentation</a></li>
				</ul>
			</section>

			<section>
				<h1>Thanks!</h1>
				<h2><a href="https://soledadpenades.com">soledadpenades.com</a> / @supersole</h2>
			</section>
			
		</main>
		<script src="vendor/decky.js"></script>
		<script src="js/main.js"></script>
	</body>
</html>
